use merkle_tox_core::cas::{BlobData, BlobInfo, BlobStatus};
use merkle_tox_core::dag::{
    ChainKey, Content, ConversationId, Ed25519Signature, KConv, LogicalIdentityPk, MerkleNode,
    NodeAuth, NodeHash, NodeMac, NodeType, PhysicalDevicePk, WireFlags, WireNode,
};
use merkle_tox_core::sync::{FullStore, SyncRange};
use merkle_tox_core::vfs::StdFileSystem;
use merkle_tox_fs::FsStore;
use merkle_tox_sqlite::Storage as SqliteStore;
use std::collections::HashSet;
use std::path::Path;
use std::sync::Arc;
use tempfile::TempDir;

fn create_sqlite(path: &Path) -> SqliteStore {
    SqliteStore::open(path.join("test.db")).unwrap()
}

fn create_fs(path: &Path) -> FsStore {
    FsStore::new(path.join("fs_root"), Arc::new(StdFileSystem)).unwrap()
}

fn make_node(parents: Vec<NodeHash>, seq: u64, rank: u64) -> MerkleNode {
    MerkleNode {
        parents,
        author_pk: LogicalIdentityPk::from([1u8; 32]),
        sender_pk: PhysicalDevicePk::from([1u8; 32]),
        sequence_number: seq,
        topological_rank: rank,
        network_timestamp: 1000,
        content: Content::Text(format!("Node {}", seq)),
        metadata: vec![],
        authentication: NodeAuth::Mac(NodeMac::from([0u8; 32])),
    }
}

fn run_compliance_test<F>(test: F)
where
    F: Fn(&dyn FullStore),
{
    let tmp = TempDir::new().unwrap();
    let path = tmp.path();

    let sqlite = create_sqlite(path);
    test(&sqlite);

    let fs = create_fs(path);
    test(&fs);
}

#[test]
fn test_store_compliance_basic_dag() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xCCu8; 32]);

        // 1. Authorize initial state (Genesis)
        let genesis = make_node(vec![], 1, 0);
        let gen_hash = genesis.hash();

        store.put_node(&conv_id, genesis.clone(), true).unwrap();
        store.set_heads(&conv_id, vec![gen_hash]).unwrap();

        // 2. Add some nodes concurrently
        let node_a = make_node(vec![gen_hash], 2, 1);
        let hash_a = node_a.hash();
        let node_b = make_node(vec![gen_hash], 3, 1);
        let hash_b = node_b.hash();

        store.put_node(&conv_id, node_a.clone(), true).unwrap();
        store.put_node(&conv_id, node_b.clone(), true).unwrap();
        store.set_heads(&conv_id, vec![hash_a, hash_b]).unwrap();

        // 3. Compare state
        let heads: HashSet<_> = store.get_heads(&conv_id).into_iter().collect();
        assert_eq!(heads.len(), 2);
        assert!(heads.contains(&hash_a));
        assert!(heads.contains(&hash_b));

        assert_eq!(
            store.get_last_sequence_number(&conv_id, &PhysicalDevicePk::from([1u8; 32])),
            3
        );
        assert_eq!(store.get_rank(&hash_a), Some(1));
        assert_eq!(store.get_node_type(&hash_a), Some(NodeType::Content));

        let retrieved = store.get_node(&hash_a).unwrap();
        assert_eq!(retrieved.hash(), hash_a);
    });
}

#[test]
fn test_store_compliance_key_management() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xDDu8; 32]);

        let k1 = KConv::from([0x11u8; 32]);
        let k2 = KConv::from([0x22u8; 32]);

        store.put_conversation_key(&conv_id, 0, k1.clone()).unwrap();
        store.put_conversation_key(&conv_id, 1, k2.clone()).unwrap();
        store.update_epoch_metadata(&conv_id, 100, 5000).unwrap();

        // Compare
        let keys = store.get_conversation_keys(&conv_id).unwrap();
        assert_eq!(keys.len(), 2);
        assert_eq!(keys[0], (0, k1));
        assert_eq!(keys[1], (1, k2));

        let meta = store.get_epoch_metadata(&conv_id).unwrap().unwrap();
        assert_eq!(meta, (100, 5000));
    });
}

#[test]
fn test_store_compliance_multi_conversation() {
    run_compliance_test(|store| {
        let conv1 = ConversationId::from([0x01u8; 32]);
        let conv2 = ConversationId::from([0x02u8; 32]);

        let node1 = make_node(vec![], 1, 0);
        let node2 = make_node(vec![], 100, 0);

        store.put_node(&conv1, node1.clone(), true).unwrap();
        store.set_heads(&conv1, vec![node1.hash()]).unwrap();

        store.put_node(&conv2, node2.clone(), true).unwrap();
        store.set_heads(&conv2, vec![node2.hash()]).unwrap();

        assert_eq!(
            store.get_last_sequence_number(&conv1, &PhysicalDevicePk::from([1u8; 32])),
            1
        );
        assert_eq!(
            store.get_last_sequence_number(&conv2, &PhysicalDevicePk::from([1u8; 32])),
            100
        );

        let heads1 = store.get_heads(&conv1);
        let heads2 = store.get_heads(&conv2);
        assert_eq!(heads1, vec![node1.hash()]);
        assert_eq!(heads2, vec![node2.hash()]);
    });
}

#[test]
fn test_store_compliance_persistence() {
    type StoreFactory = Box<dyn Fn(&Path) -> Box<dyn FullStore>>;
    let factories: Vec<(&str, StoreFactory)> = vec![
        ("sqlite", Box::new(|p| Box::new(create_sqlite(p)))),
        ("fs", Box::new(|p| Box::new(create_fs(p)))),
    ];

    for (name, factory) in factories {
        let tmp_path = TempDir::new().unwrap();
        let path = tmp_path.path();
        let conv_id = ConversationId::from([0xEEu8; 32]);
        let node = make_node(vec![], 1, 0);
        let hash = node.hash();

        {
            let store = factory(path);
            store.put_node(&conv_id, node.clone(), true).unwrap();
            store.set_heads(&conv_id, vec![hash]).unwrap();
        }

        // Re-open and verify
        let store = factory(path);
        assert_eq!(
            store.get_heads(&conv_id),
            vec![hash],
            "Persistence failed for {}",
            name
        );
        assert_eq!(
            store.get_node(&hash).unwrap().hash(),
            hash,
            "Persistence failed for {}",
            name
        );
        assert_eq!(
            store.get_last_sequence_number(&conv_id, &PhysicalDevicePk::from([1u8; 32])),
            1,
            "Persistence failed for {}",
            name
        );
    }
}

#[test]
fn test_store_compliance_blobs() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xAAu8; 32]);

        let blob_hash = NodeHash::from([0xBBu8; 32]);
        let info = BlobInfo {
            hash: blob_hash,
            size: 1024,
            bao_root: Some([0xCCu8; 32]),
            status: BlobStatus::Downloading,
            received_mask: None,
        };

        let data = vec![0x42u8; 1024];

        store.put_blob_info(info.clone()).unwrap();
        store
            .put_chunk(&conv_id, &blob_hash, 0, &data, None)
            .unwrap();

        assert!(store.has_blob(&blob_hash));
        let retrieved_info = store.get_blob_info(&blob_hash).unwrap();
        assert_eq!(retrieved_info.status, BlobStatus::Available);

        let retrieved_data = store.get_chunk(&blob_hash, 0, 1024).unwrap();
        assert_eq!(retrieved_data, data);
    });
}

#[test]
fn test_store_compliance_overwrite_semantics() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x11u8; 32]);
        let node = make_node(vec![], 1, 10);
        let hash = node.hash();

        // Put node twice, first unverified then verified
        store.put_node(&conv_id, node.clone(), false).unwrap();
        assert_eq!(store.get_speculative_nodes(&conv_id).len(), 1);

        store.put_node(&conv_id, node.clone(), true).unwrap();
        // Depending on implementation, put_node(verified=true) might or might not promote a speculative node.
        // In SqliteStore, it uses INSERT OR IGNORE, so it won't update the status!
        // This is a potential bug or at least a behavior to document.
        // Verify that mark_verified correctly handles the node.
        store.mark_verified(&conv_id, &hash).unwrap();
        assert_eq!(store.get_speculative_nodes(&conv_id).len(), 0);

        // Global Offset overwrite
        store.set_global_offset(100).unwrap();
        store.set_global_offset(200).unwrap();
        assert_eq!(store.get_global_offset(), Some(200));

        // Key overwrite
        let k1 = KConv::from([1u8; 32]);
        let k2 = KConv::from([2u8; 32]);
        store.put_conversation_key(&conv_id, 0, k1.clone()).unwrap();
        store.put_conversation_key(&conv_id, 0, k2.clone()).unwrap();
        let keys = store.get_conversation_keys(&conv_id).unwrap();
        assert_eq!(keys.len(), 1);
        assert_eq!(keys[0].1, k2);
    });
}

#[test]
fn test_store_compliance_blob_transitions() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x22u8; 32]);
        let hash = NodeHash::from([0x33u8; 32]);
        let total_size = 128 * 1024; // 2 chunks
        let info = BlobInfo {
            hash,
            size: total_size,
            bao_root: None,
            status: BlobStatus::Pending,
            received_mask: None,
        };

        store.put_blob_info(info).unwrap();
        assert_eq!(
            store.get_blob_info(&hash).unwrap().status,
            BlobStatus::Pending
        );

        let data1 = vec![0xAAu8; 64 * 1024];
        let data2 = vec![0xBBu8; 64 * 1024];

        // Put second chunk first
        store
            .put_chunk(&conv_id, &hash, 64 * 1024, &data2, None)
            .unwrap();
        let info = store.get_blob_info(&hash).unwrap();
        assert_eq!(info.status, BlobStatus::Downloading);

        // Put first chunk
        store.put_chunk(&conv_id, &hash, 0, &data1, None).unwrap();
        let info = store.get_blob_info(&hash).unwrap();
        assert_eq!(info.status, BlobStatus::Available);

        assert_eq!(store.get_chunk(&hash, 0, 64 * 1024).unwrap(), data1);
        assert_eq!(store.get_chunk(&hash, 64 * 1024, 64 * 1024).unwrap(), data2);
    });
}

#[test]
fn test_store_compliance_boundary_conditions() {
    run_compliance_test(|store| {
        let hash = NodeHash::from([0x44u8; 32]);
        let conv_id = ConversationId::from([0x55u8; 32]);
        let data = vec![1, 2, 3, 4, 5];
        let info = BlobInfo {
            hash,
            size: 5,
            bao_root: None,
            status: BlobStatus::Available,
            received_mask: None,
        };

        store.put_blob_info(info).unwrap();
        store.put_chunk(&conv_id, &hash, 0, &data, None).unwrap();

        // 0-byte read
        assert_eq!(store.get_chunk(&hash, 0, 0).unwrap().len(), 0);

        // Read at end
        assert!(store.get_chunk(&hash, 5, 1).is_err());

        // Read past end
        assert!(store.get_chunk(&hash, 10, 1).is_err());

        // Partial read
        assert_eq!(store.get_chunk(&hash, 2, 2).unwrap(), vec![3, 4]);

        let fake_hash = NodeHash::from([0xFFu8; 32]);
        assert!(store.get_node(&fake_hash).is_none());
        assert!(store.get_blob_info(&fake_hash).is_none());
        assert!(store.get_chunk(&fake_hash, 0, 1).is_err());
    });
}

#[test]
fn test_store_compliance_large_values() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x66u8; 32]);
        let large_seq = u64::MAX / 2 + 100; // Larger than i64::MAX
        let large_rank = u64::MAX - 1;

        let node = make_node(vec![], large_seq, large_rank);
        let hash = node.hash();

        store.put_node(&conv_id, node.clone(), true).unwrap();

        assert_eq!(
            store.get_last_sequence_number(&conv_id, &PhysicalDevicePk::from([1u8; 32])),
            large_seq
        );
        assert_eq!(store.get_rank(&hash), Some(large_rank));

        let retrieved = store.get_node(&hash).unwrap();
        assert_eq!(retrieved.sequence_number, large_seq);
        assert_eq!(retrieved.topological_rank, large_rank);
    });
}

#[test]
fn test_store_compliance_speculative_promotion() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x77u8; 32]);
        let node1 = make_node(vec![], 1, 0);
        let node2 = make_node(vec![], 2, 1);
        let h1 = node1.hash();
        let h2 = node2.hash();

        store.put_node(&conv_id, node1.clone(), false).unwrap();
        store.put_node(&conv_id, node2.clone(), false).unwrap();

        let speculative = store.get_speculative_nodes(&conv_id);
        assert_eq!(speculative.len(), 2);

        let hashes: HashSet<_> = speculative.iter().map(|n| n.hash()).collect();
        assert!(hashes.contains(&h1));
        assert!(hashes.contains(&h2));

        // Promote node1
        store.mark_verified(&conv_id, &h1).unwrap();

        let speculative = store.get_speculative_nodes(&conv_id);
        assert_eq!(speculative.len(), 1);
        assert_eq!(speculative[0].hash(), h2);

        // Promote node2
        store.mark_verified(&conv_id, &h2).unwrap();
        assert_eq!(store.get_speculative_nodes(&conv_id).len(), 0);
    });
}

#[test]
fn test_store_compliance_admin_tracks() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x33u8; 32]);
        let h1 = NodeHash::from([0x44u8; 32]);
        let h2 = NodeHash::from([0x55u8; 32]);

        store.set_admin_heads(&conv_id, vec![h1, h2]).unwrap();
        let heads: HashSet<_> = store.get_admin_heads(&conv_id).into_iter().collect();
        assert_eq!(heads.len(), 2);
        assert!(heads.contains(&h1));
        assert!(heads.contains(&h2));
    });
}

#[test]
fn test_store_compliance_wire_nodes() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x66u8; 32]);
        let hash = NodeHash::from([0x77u8; 32]);
        let wire = WireNode {
            parents: vec![],
            author_pk: LogicalIdentityPk::from([1u8; 32]),
            encrypted_payload: vec![1, 2, 3, 4],
            topological_rank: 5,
            network_timestamp: 1000,
            flags: WireFlags::ENCRYPTED,
            authentication: NodeAuth::Mac(NodeMac::from([0u8; 32])),
        };

        store.put_wire_node(&conv_id, &hash, wire.clone()).unwrap();
        assert!(
            store
                .get_opaque_node_hashes(&conv_id)
                .unwrap()
                .contains(&hash)
        );

        let retrieved = store.get_wire_node(&hash).unwrap();
        assert_eq!(retrieved.encrypted_payload, wire.encrypted_payload);

        store.remove_wire_node(&conv_id, &hash).unwrap();
        assert!(store.get_wire_node(&hash).is_none());
    });
}

#[test]
fn test_store_compliance_advanced_queries() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x88u8; 32]);

        // Add nodes with different ranks
        for i in 1..=5 {
            let node = make_node(vec![], i as u64, i as u64);
            store.put_node(&conv_id, node, true).unwrap();
        }

        // Test get_verified_nodes_by_type
        let nodes = store
            .get_verified_nodes_by_type(&conv_id, NodeType::Content)
            .unwrap();
        assert_eq!(nodes.len(), 5);
        for i in 0..4 {
            assert!(nodes[i].topological_rank <= nodes[i + 1].topological_rank);
        }

        // Test get_node_hashes_in_range
        let range = SyncRange {
            epoch: 0,
            min_rank: 2,
            max_rank: 4,
        };
        let hashes = store.get_node_hashes_in_range(&conv_id, &range).unwrap();
        assert_eq!(hashes.len(), 3);
    });
}

#[test]
fn test_store_compliance_ratchet_keys() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x99u8; 32]);
        let hash = NodeHash::from([0xAAu8; 32]);
        let key = ChainKey::from([0xBBu8; 32]);

        store
            .put_ratchet_key(&conv_id, &hash, key.clone(), 0)
            .unwrap();
        let retrieved = store.get_ratchet_key(&conv_id, &hash).unwrap().unwrap();
        assert_eq!(retrieved, (key, 0));

        store.remove_ratchet_key(&conv_id, &hash).unwrap();
        assert!(store.get_ratchet_key(&conv_id, &hash).unwrap().is_none());
    });
}

#[test]
fn test_store_compliance_reconciliation_sketches() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xCCu8; 32]);
        let range = SyncRange {
            epoch: 1,
            min_rank: 10,
            max_rank: 20,
        };
        let sketch = vec![1, 2, 3, 4, 5];

        store.put_sketch(&conv_id, &range, &sketch).unwrap();
        let retrieved = store.get_sketch(&conv_id, &range).unwrap().unwrap();
        assert_eq!(retrieved, sketch);
    });
}

#[test]
fn test_store_compliance_diagnostics() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xDDu8; 32]);
        let n1 = make_node(vec![], 1, 0);
        let n2 = make_node(vec![], 2, 1);
        let h1 = n1.hash();

        store.put_node(&conv_id, n1.clone(), true).unwrap();
        store.put_node(&conv_id, n2.clone(), false).unwrap();

        let (verified, speculative) = store.get_node_counts(&conv_id);
        assert_eq!(verified, 1);
        assert_eq!(speculative, 1);

        assert!(store.contains_node(&h1));
        assert!(store.is_verified(&h1));
        assert!(!store.is_verified(&n2.hash()));

        assert!(store.size_bytes() > 0);

        // has_children
        let n3 = make_node(vec![h1], 3, 1);
        store.put_node(&conv_id, n3, true).unwrap();
        assert!(store.has_children(&h1));
    });
}

#[test]
fn test_store_compliance_blob_proofs() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xEEu8; 32]);
        let hash = NodeHash::from([0xFFu8; 32]);
        let data = vec![0x55u8; 1024];
        let info = BlobInfo {
            hash,
            size: 1024,
            bao_root: None,
            status: BlobStatus::Available,
            received_mask: None,
        };

        store.put_blob_info(info).unwrap();
        store.put_chunk(&conv_id, &hash, 0, &data, None).unwrap();

        let (retrieved_data, _proof) = store.get_chunk_with_proof(&hash, 0, 1024).unwrap();
        assert_eq!(retrieved_data, data);
        // For a 1024 byte blob, the proof might be empty as it fits in a single chunk,
        // but it depends on the Bao implementation details.
    });
}

#[test]
fn test_store_compliance_multi_device_sequences() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x12u8; 32]);
        let dev1 = PhysicalDevicePk::from([0x01u8; 32]);
        let dev2 = PhysicalDevicePk::from([0x02u8; 32]);

        let mut node1 = make_node(vec![], 10, 0);
        node1.sender_pk = dev1;
        let mut node2 = make_node(vec![], 20, 0);
        node2.sender_pk = dev2;

        store.put_node(&conv_id, node1, true).unwrap();
        store.put_node(&conv_id, node2, true).unwrap();

        assert_eq!(store.get_last_sequence_number(&conv_id, &dev1), 10);
        assert_eq!(store.get_last_sequence_number(&conv_id, &dev2), 20);
    });
}

#[test]
fn test_store_compliance_epoch_metadata_updates() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x34u8; 32]);

        store.update_epoch_metadata(&conv_id, 10, 1000).unwrap();
        let meta = store.get_epoch_metadata(&conv_id).unwrap().unwrap();
        assert_eq!(meta, (10, 1000));

        store.update_epoch_metadata(&conv_id, 20, 2000).unwrap();
        let meta = store.get_epoch_metadata(&conv_id).unwrap().unwrap();
        assert_eq!(meta, (20, 2000));
    });
}

#[test]
fn test_store_compliance_range_edge_cases() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x56u8; 32]);
        for i in 1..=3 {
            let node = make_node(vec![], i, i);
            store.put_node(&conv_id, node, true).unwrap();
        }

        // Exact match
        let range = SyncRange {
            epoch: 0,
            min_rank: 2,
            max_rank: 2,
        };
        assert_eq!(
            store
                .get_node_hashes_in_range(&conv_id, &range)
                .unwrap()
                .len(),
            1
        );

        // Reversed range
        let range = SyncRange {
            epoch: 0,
            min_rank: 3,
            max_rank: 1,
        };
        assert_eq!(
            store
                .get_node_hashes_in_range(&conv_id, &range)
                .unwrap()
                .len(),
            0
        );

        // Out of bounds
        let range = SyncRange {
            epoch: 0,
            min_rank: 10,
            max_rank: 20,
        };
        assert_eq!(
            store
                .get_node_hashes_in_range(&conv_id, &range)
                .unwrap()
                .len(),
            0
        );
    });
}

#[test]
fn test_store_compliance_speculative_promotion_consistency() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x78u8; 32]);
        let node = make_node(vec![], 1, 10);
        let hash = node.hash();

        // 1. Put as speculative
        store.put_node(&conv_id, node.clone(), false).unwrap();
        assert!(!store.is_verified(&hash));
        assert_eq!(store.get_speculative_nodes(&conv_id).len(), 1);

        // 2. Put again as verified - this should promote it
        store.put_node(&conv_id, node, true).unwrap();

        // Note: Some stores might require explicit mark_verified if put_node is idempotent on hash.
        // We test if it *can* be promoted via put_node.
        if store.get_speculative_nodes(&conv_id).is_empty() {
            assert!(store.is_verified(&hash));
        } else {
            // If it didn't promote, we mark it verified explicitly.
            store.mark_verified(&conv_id, &hash).unwrap();
            assert!(store.is_verified(&hash));
            assert_eq!(store.get_speculative_nodes(&conv_id).len(), 0);
        }
    });
}

#[test]
fn test_store_compliance_blob_chunk_proofs() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x90u8; 32]);
        let hash = NodeHash::from([0x01u8; 32]);
        let data = vec![0xAAu8; 1024];
        let proof = vec![0xBBu8; 64];
        let info = BlobInfo {
            hash,
            size: 1024,
            bao_root: None,
            status: BlobStatus::Pending,
            received_mask: None,
        };

        store.put_blob_info(info).unwrap();
        store
            .put_chunk(&conv_id, &hash, 0, &data, Some(&proof))
            .unwrap();

        let (retrieved_data, retrieved_proof) = store.get_chunk_with_proof(&hash, 0, 1024).unwrap();
        assert_eq!(retrieved_data, data);

        // If the store supports proofs, it should return a valid proof.
        // If we provided a junk proof during put_chunk, the store might have
        // ignored it and generated a real one upon completion.
        if !retrieved_proof.is_empty() {
            // Check if it's at least a valid proof for the data if we have a root.
            if let Some(info) = store.get_blob_info(&hash)
                && let Some(root) = info.bao_root
            {
                let blob_data = BlobData {
                    hash,
                    offset: 0,
                    data: retrieved_data,
                    proof: retrieved_proof,
                };
                assert!(blob_data.verify(&root));
            }
        }
    });
}

#[test]
fn test_store_compliance_has_node() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xABu8; 32]);
        let node = make_node(vec![], 1, 1);
        let hash = node.hash();

        assert!(!store.has_node(&hash));
        store.put_node(&conv_id, node, true).unwrap();
        assert!(store.has_node(&hash));
    });
}

#[test]
fn test_store_compliance_has_children_none() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xBCu8; 32]);
        let node = make_node(vec![], 1, 1);
        let hash = node.hash();
        store.put_node(&conv_id, node, true).unwrap();
        assert!(!store.has_children(&hash));
    });
}

#[test]
fn test_store_compliance_multiple_opaque_nodes() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0xCDu8; 32]);
        let h1 = NodeHash::from([0x11u8; 32]);
        let h2 = NodeHash::from([0x22u8; 32]);
        let wire = WireNode {
            parents: vec![],
            author_pk: LogicalIdentityPk::from([1u8; 32]),
            encrypted_payload: vec![1, 2, 3, 4],
            topological_rank: 5,
            network_timestamp: 1000,
            flags: WireFlags::ENCRYPTED,
            authentication: NodeAuth::Mac(NodeMac::from([0u8; 32])),
        };

        store.put_wire_node(&conv_id, &h1, wire.clone()).unwrap();
        store.put_wire_node(&conv_id, &h2, wire).unwrap();

        let opaque = store.get_opaque_node_hashes(&conv_id).unwrap();
        assert_eq!(opaque.len(), 2);
        let set: HashSet<_> = opaque.into_iter().collect();
        assert!(set.contains(&h1));
        assert!(set.contains(&h2));
    });
}

#[test]
fn test_store_compliance_empty_size() {
    run_compliance_test(|store| {
        // Should be small but possibly non-zero if there's header overhead
        let size = store.size_bytes();
        assert!(size < 1024 * 1024); // Reasonable upper bound for empty store
    });
}

#[test]
fn test_store_compliance_bao_verification() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x91u8; 32]);
        let data = vec![0xCCu8; 1024 * 128]; // 2 chunks
        let blob_hash = NodeHash::from(*blake3::hash(&data).as_bytes());

        let info = BlobInfo {
            hash: blob_hash,
            size: data.len() as u64,
            bao_root: None,
            status: BlobStatus::Pending,
            received_mask: None,
        };

        store.put_blob_info(info).unwrap();
        store
            .put_chunk(&conv_id, &blob_hash, 0, &data[..65536], None)
            .unwrap();
        store
            .put_chunk(&conv_id, &blob_hash, 65536, &data[65536..], None)
            .unwrap();

        let info = store.get_blob_info(&blob_hash).unwrap();
        // If it's available, it might have a root (FS backend does this automatically in put_chunk completion)
        if let Some(root) = info.bao_root {
            let (chunk, proof) = store.get_chunk_with_proof(&blob_hash, 0, 65536).unwrap();
            let blob_data = BlobData {
                hash: blob_hash,
                offset: 0,
                data: chunk,
                proof: proof.clone(),
            };
            assert!(
                blob_data.verify(&root),
                "Bao verification failed for {:?}",
                blob_hash
            );
            assert!(
                !proof.is_empty(),
                "Bao proof should not be empty for a multi-chunk blob"
            );
        } else if info.status == BlobStatus::Available {
            panic!("Blob is Available but has no bao_root");
        }
    });
}

#[test]
fn test_store_compliance_opaque_eviction() {
    run_compliance_test(|store| {
        let conv_id = ConversationId::from([0x92u8; 32]);

        // 1. Add an Admin node (Anchor)
        let admin_wire = WireNode {
            parents: vec![],
            author_pk: LogicalIdentityPk::from([0u8; 32]),
            encrypted_payload: vec![0u8; 32],
            topological_rank: 0,
            network_timestamp: 0,
            flags: WireFlags::NONE,
            authentication: NodeAuth::Signature(Ed25519Signature::from([1u8; 64])),
        };
        let admin_data = tox_proto::serialize(&admin_wire).unwrap();
        let admin_hash = NodeHash::from(*blake3::hash(&admin_data).as_bytes());
        store
            .put_wire_node(&conv_id, &admin_hash, admin_wire)
            .unwrap();

        // 2. Fill with 110MB of junk (limit is 100MB)
        let junk_payload = vec![0u8; 1024 * 1024]; // 1MB
        for i in 0..110 {
            let mut junk_wire = WireNode {
                parents: vec![],
                author_pk: LogicalIdentityPk::from([1u8; 32]),
                encrypted_payload: junk_payload.clone(),
                topological_rank: i as u64 + 1,
                network_timestamp: i as i64 + 1,
                flags: WireFlags::ENCRYPTED,
                authentication: NodeAuth::Mac(NodeMac::from([0u8; 32])),
            };
            // Ensure unique hash
            junk_wire.encrypted_payload[0] = (i % 256) as u8;
            let data = tox_proto::serialize(&junk_wire).unwrap();
            let hash = NodeHash::from(*blake3::hash(&data).as_bytes());
            store.put_wire_node(&conv_id, &hash, junk_wire).unwrap();
        }

        // 3. Verify total size is bounded or nodes are evicted
        assert!(
            store.get_wire_node(&admin_hash).is_some(),
            "Anchor node was evicted!"
        );

        let opaque_hashes = store.get_opaque_node_hashes(&conv_id).unwrap();
        assert!(
            opaque_hashes.len() <= 105,
            "Eviction failed: too many opaque nodes ({})",
            opaque_hashes.len()
        );
    });
}

// end of file
